{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/JD23tamu/MS_Analytics_Project2/main/data/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which is target variable?**\n",
    "\n",
    "Taget variable is HeartDisease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Duplicates:', len(df[df.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check counts for heart disease or not\n",
    "# balanced or not?\n",
    "round(df['HeartDisease'].value_counts()/len(df['HeartDisease'])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable of this dataset, is mostly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = df[df['HeartDisease'] == 1]\n",
    "fig, ax = plt.subplots(figsize =(10, 10))\n",
    "fig.patch.set_facecolor('#f1faee')\n",
    "\n",
    "j = 1\n",
    "for i in heart_df.columns: \n",
    "    if heart_df[i].dtypes  == 'object':\n",
    "        plt.subplot(3, 2, j)\n",
    "        sns.countplot(y = heart_df[i], data = heart_df, order=heart_df[i].value_counts().index, palette='Blues_r', edgecolor='black')\n",
    "        #plt.title(i, fontsize=15, color='black')\n",
    "        plt.suptitle('Categorical Variables', fontsize=20)\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above graph shows: \n",
    "\n",
    "* Male getting more heartdisease than female\n",
    "* Asymptomatic chest pain shows more heartdisease\n",
    "* Exercise Angina showing more heartdisease\n",
    "* ST Slope Flat has more heartdisease\n",
    "\n",
    "Found same result form co-relation matrix plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric variables distribution and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "num_col = df[col]\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 10))\n",
    "fig.patch.set_facecolor('#f1faee')\n",
    "\n",
    "c = 1\n",
    "for i in num_col.columns: \n",
    "        plt.subplot(3, 2, c)\n",
    "        plt.boxplot(num_col[i])\n",
    "        plt.title(i, fontsize=12, color='Black')\n",
    "        plt.suptitle('Numeric Variables', fontsize=20)\n",
    "        c = c + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above histogram shows:\n",
    "\n",
    "* Age is unimodal but slightly skewed to left and no outliers\n",
    "* RetingBP is unimodal and normally distributed, has outliers\n",
    "* Cholesterol is bi-modal and has outliers\n",
    "* Maximun heart rate is unimodal and normally distributed has couple of outliers\n",
    "* Old peak is bi-modal and slightly skewed towards right and has some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variables\n",
    "pd.set_option('display.max_columns', 40)\n",
    "\n",
    "# Select categorical variables\n",
    "cat = df.select_dtypes(include=object).columns\n",
    "df_dummy = pd.get_dummies(df, columns=cat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "### \n",
    "Logistic regression is used to obtain odds ratio in the presence of more than one explanatory variable.  \n",
    "The procedure is quite similar to multiple linear regression, with the exception that the response variable is binomial.  \n",
    "The result is the impact of each variable on the odds ratio of the observed event of interest.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Normalization\n",
    "\n",
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = df_dummy.drop(columns='HeartDisease')\n",
    "out = df_dummy['HeartDisease']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    inp, out, test_size=0.20, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred_lr = log_reg.predict(x_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred_lr), 3))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred_lr), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Standardization\n",
    "\n",
    "### Model 2\n",
    "\n",
    "From the sklearn library, we need to use StandardScaler to implement Standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# input, output var declarations \n",
    "Y = df_dummy['HeartDisease']\n",
    "X = df_dummy[['Age','RestingBP','Cholesterol','FastingBS','MaxHR','Oldpeak']]\n",
    "columns = X.columns\n",
    "# apply Standardization\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std = pd.DataFrame(X_std, columns = columns)\n",
    "# Dataset of all dummy columns\n",
    "df2 = df_dummy.iloc[:,7:]\n",
    "# Merge the Standardization column with dummy columns\n",
    "X_nr = X_std.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_nr, Y, test_size=0.20, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_nr = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "y_pred_lr_nr = log_reg_nr.predict(x_test)\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred_lr_nr), 3))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred_lr_nr), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Imputation\n",
    "\n",
    "Will Work on this, later!\n",
    "\n",
    "From the outliers plot, we see 4 columns have outliers. Replace outliers with Median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Logistic Regression\n",
    "\n",
    "TP  FP\n",
    "FN  TN\n",
    "If errors must be, better to have more FP than FN as shown in this confusion matrix.  \n",
    "It's better to be sure, than miss an event.  \n",
    "The F1 Score is the 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLabels: np.ndarray = log_reg_nr.predict(x_test)\n",
    "confusionMatrixDF: pd.DataFrame = pd.DataFrame(metrics.confusion_matrix(y_test,predictedLabels),index=['Actual +','Actual -'],columns=['Predicted +', 'Predicted -'])\n",
    "print(confusionMatrixDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "rf = RandomForestClassifier(random_state=20, n_estimators=100)\n",
    " \n",
    "# x_train, x_test, y_train, y_test\n",
    "rf = rf.fit(x_train, y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred_rf), 3))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred_rf), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4\n",
    "\n",
    "Tuned to the model to assign parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300]\n",
    "max_depth = [10, 20, 30]\n",
    "max_depth.append(None)\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_split = [5, 10, 15]\n",
    "min_samples_leaf = [1, 2]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "          'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "          'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "RF = RandomForestClassifier(random_state=20)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RF, \n",
    "                           param_grid = params,\n",
    "                           scoring = 'f1',\n",
    "                           cv = 5,\n",
    "                           verbose=0, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"best score: \", grid_search.best_score_)\n",
    "print(\"best param: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_para = grid_search.best_params_\n",
    "rf_2 = RandomForestClassifier(random_state=20, **best_para)\n",
    "                            \n",
    "rf_2 = rf_2.fit(x_train, y_train)\n",
    "y_pred_rf_2 = rf_2.predict(x_test)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test, y_pred_rf_2), 3))\n",
    "print('F1 Score: ', round(f1_score(y_test, y_pred_rf_2), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_rf_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_rf_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "plt.figure(figsize=(15,8))\n",
    "imp = mutual_info_classif(inp, out)\n",
    "feature_imp = pd.Series(imp, df_dummy.columns[0:len(df_dummy.columns)-1])\n",
    "feature_imp = feature_imp.sort_values(ascending=True)\n",
    "feature_imp.plot(kind = 'barh', color = 'teal')\n",
    "plt.title(\"Feature importance plot\")\n",
    "plt.savefig(\"images\\\\featureImportance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets select top 10 features and apply random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 5 \n",
    "\n",
    "Random forest model with top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feat_df = df_dummy[['ST_Slope_Flat','Sex_M','ST_Slope_Down','RestingECG_ST','ExerciseAngina_N', \n",
    "                         'Oldpeak','ChestPainType_ASY','MaxHR','Sex_F','Cholesterol','HeartDisease']]\n",
    "\n",
    "inp_feat = best_feat_df.drop(columns='HeartDisease')\n",
    "out_feat = best_feat_df['HeartDisease']\n",
    "\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(\n",
    "    inp_feat, out_feat, test_size=0.20, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feat = RandomForestClassifier(random_state=20, n_estimators=100)\n",
    " \n",
    "rf_feat = rf_feat.fit(x_train_2, y_train_2)\n",
    "y_pred_rf_feat = rf_feat.predict(x_test_2)\n",
    "\n",
    "print('Accuracy score: ', round(accuracy_score(y_test_2, y_pred_rf_feat), 3))\n",
    "print('F1 Score: ', round(f1_score(y_test_2, y_pred_rf_feat), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random forest model with all the features gives highest accuracy.\n",
    "\n",
    "Out of all 4 models Random forest performs better. The model 3 could be the potential best fit for our data. Moreover, accuracy is 89%.\n",
    "The model is confusion matrix shows:\n",
    "\n",
    "    * True Positive = 71\n",
    "    * False Positive = 14\n",
    "    * False Negative = 6\n",
    "    * True Negative = 93\n",
    "\n",
    "The model is producing fewer False Negatives than False Positives.\n",
    "\n",
    "There is definitely room for improvement. In this project we tried to implement 2 supervised models i.e Logistic and Random forest. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
