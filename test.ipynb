{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creation of the directory images failed; it already exists.\n",
      "\n",
      "\n",
      "Creation of the directory data failed; it already exists.\n",
      "\n",
      "Basic stats on data:\n",
      "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
      "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
      "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
      "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
      "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
      "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
      "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
      "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
      "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
      "\n",
      "          Oldpeak  HeartDisease  \n",
      "count  918.000000    918.000000  \n",
      "mean     0.887364      0.553377  \n",
      "std      1.066570      0.497414  \n",
      "min     -2.600000      0.000000  \n",
      "25%      0.000000      0.000000  \n",
      "50%      0.600000      1.000000  \n",
      "75%      1.500000      1.000000  \n",
      "max      6.200000      1.000000  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n",
      "Data info:\n",
      "None\n",
      "\n",
      "\n",
      "Number of Duplicates:\n",
      " 0\n",
      "\n",
      "Counts\n",
      "Age               918\n",
      "Sex               918\n",
      "ChestPainType     918\n",
      "RestingBP         918\n",
      "Cholesterol       918\n",
      "FastingBS         918\n",
      "RestingECG        918\n",
      "MaxHR             918\n",
      "ExerciseAngina    918\n",
      "Oldpeak           918\n",
      "ST_Slope          918\n",
      "HeartDisease      918\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Value Counts:\n",
      "Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease\n",
      "28   M    ATA            130        132          0          LVH         185    N               0.0      Up        0               1\n",
      "58   M    ASY            128        216          0          LVH         131    Y               2.2      Flat      1               1\n",
      "                         130        0            0          ST          100    Y               1.0      Flat      1               1\n",
      "                                    263          0          Normal      140    Y               2.0      Flat      1               1\n",
      "                         132        458          1          Normal      69     N               1.0      Down      0               1\n",
      "                                                                                                                                 ..\n",
      "50   M    ASY            150        215          0          Normal      140    Y               0.0      Up        0               1\n",
      "                                    243          0          LVH         128    N               2.6      Flat      1               1\n",
      "          ATA            120        168          0          Normal      160    N               0.0      Up        0               1\n",
      "                         140        216          0          Normal      170    N               0.0      Up        0               1\n",
      "77   M    ASY            125        304          0          LVH         162    Y               0.0      Up        1               1\n",
      "Length: 918, dtype: int64\n",
      "Nulls:\n",
      "      Age   Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
      "0    True  True           True       True         True       True        True   \n",
      "1    True  True           True       True         True       True        True   \n",
      "2    True  True           True       True         True       True        True   \n",
      "3    True  True           True       True         True       True        True   \n",
      "4    True  True           True       True         True       True        True   \n",
      "..    ...   ...            ...        ...          ...        ...         ...   \n",
      "913  True  True           True       True         True       True        True   \n",
      "914  True  True           True       True         True       True        True   \n",
      "915  True  True           True       True         True       True        True   \n",
      "916  True  True           True       True         True       True        True   \n",
      "917  True  True           True       True         True       True        True   \n",
      "\n",
      "     MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
      "0     True            True     True      True          True  \n",
      "1     True            True     True      True          True  \n",
      "2     True            True     True      True          True  \n",
      "3     True            True     True      True          True  \n",
      "4     True            True     True      True          True  \n",
      "..     ...             ...      ...       ...           ...  \n",
      "913   True            True     True      True          True  \n",
      "914   True            True     True      True          True  \n",
      "915   True            True     True      True          True  \n",
      "916   True            True     True      True          True  \n",
      "917   True            True     True      True          True  \n",
      "\n",
      "[918 rows x 12 columns]\n",
      "\n",
      "\n",
      "Unique values:\n",
      "Age                50\n",
      "Sex                 2\n",
      "ChestPainType       4\n",
      "RestingBP          67\n",
      "Cholesterol       222\n",
      "FastingBS           2\n",
      "RestingECG          3\n",
      "MaxHR             119\n",
      "ExerciseAngina      2\n",
      "Oldpeak            53\n",
      "ST_Slope            3\n",
      "HeartDisease        2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Nulls in cloumns: \n",
      "Age               0\n",
      "Sex               0\n",
      "ChestPainType     0\n",
      "RestingBP         0\n",
      "Cholesterol       0\n",
      "FastingBS         0\n",
      "RestingECG        0\n",
      "MaxHR             0\n",
      "ExerciseAngina    0\n",
      "Oldpeak           0\n",
      "ST_Slope          0\n",
      "HeartDisease      0\n",
      "dtype: int64\n",
      "\n",
      "Number of nulls in entire dataset: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BRUNSO~1\\AppData\\Local\\Temp/ipykernel_17964/617192159.py:75: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "C:\\Users\\BRUNSO~1\\AppData\\Local\\Temp/ipykernel_17964/617192159.py:82: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   Sex_F              918 non-null    uint8\n",
      " 1   Sex_M              918 non-null    uint8\n",
      " 2   ChestPainType_ASY  918 non-null    uint8\n",
      " 3   ChestPainType_ATA  918 non-null    uint8\n",
      " 4   ChestPainType_NAP  918 non-null    uint8\n",
      " 5   ChestPainType_TA   918 non-null    uint8\n",
      " 6   RestingECG_LVH     918 non-null    uint8\n",
      " 7   RestingECG_Normal  918 non-null    uint8\n",
      " 8   RestingECG_ST      918 non-null    uint8\n",
      " 9   ExerciseAngina_N   918 non-null    uint8\n",
      " 10  ExerciseAngina_Y   918 non-null    uint8\n",
      " 11  ST_Slope_Down      918 non-null    uint8\n",
      " 12  ST_Slope_Flat      918 non-null    uint8\n",
      " 13  ST_Slope_Up        918 non-null    uint8\n",
      "dtypes: uint8(14)\n",
      "memory usage: 12.7 KB\n",
      "None\n",
      "     Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  \\\n",
      "0     40        140          289          0    172      0.0             0   \n",
      "1     49        160          180          0    156      1.0             1   \n",
      "2     37        130          283          0     98      0.0             0   \n",
      "3     48        138          214          0    108      1.5             1   \n",
      "4     54        150          195          0    122      0.0             0   \n",
      "..   ...        ...          ...        ...    ...      ...           ...   \n",
      "913   45        110          264          0    132      1.2             1   \n",
      "914   68        144          193          1    141      3.4             1   \n",
      "915   57        130          131          0    115      1.2             1   \n",
      "916   57        130          236          0    174      0.0             1   \n",
      "917   38        138          175          0    173      0.0             0   \n",
      "\n",
      "     Sex_F  Sex_M  ChestPainType_ASY  ...  ChestPainType_NAP  \\\n",
      "0        0      1                  0  ...                  0   \n",
      "1        1      0                  0  ...                  1   \n",
      "2        0      1                  0  ...                  0   \n",
      "3        1      0                  1  ...                  0   \n",
      "4        0      1                  0  ...                  1   \n",
      "..     ...    ...                ...  ...                ...   \n",
      "913      0      1                  0  ...                  0   \n",
      "914      0      1                  1  ...                  0   \n",
      "915      0      1                  1  ...                  0   \n",
      "916      1      0                  0  ...                  0   \n",
      "917      0      1                  0  ...                  1   \n",
      "\n",
      "     ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  RestingECG_ST  \\\n",
      "0                   0               0                  1              0   \n",
      "1                   0               0                  1              0   \n",
      "2                   0               0                  0              1   \n",
      "3                   0               0                  1              0   \n",
      "4                   0               0                  1              0   \n",
      "..                ...             ...                ...            ...   \n",
      "913                 1               0                  1              0   \n",
      "914                 0               0                  1              0   \n",
      "915                 0               0                  1              0   \n",
      "916                 0               1                  0              0   \n",
      "917                 0               0                  1              0   \n",
      "\n",
      "     ExerciseAngina_N  ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  \\\n",
      "0                   1                 0              0              0   \n",
      "1                   1                 0              0              1   \n",
      "2                   1                 0              0              0   \n",
      "3                   0                 1              0              1   \n",
      "4                   1                 0              0              0   \n",
      "..                ...               ...            ...            ...   \n",
      "913                 1                 0              0              1   \n",
      "914                 1                 0              0              1   \n",
      "915                 0                 1              0              1   \n",
      "916                 1                 0              0              1   \n",
      "917                 1                 0              0              0   \n",
      "\n",
      "     ST_Slope_Up  \n",
      "0              1  \n",
      "1              0  \n",
      "2              1  \n",
      "3              0  \n",
      "4              1  \n",
      "..           ...  \n",
      "913            0  \n",
      "914            0  \n",
      "915            0  \n",
      "916            0  \n",
      "917            1  \n",
      "\n",
      "[918 rows x 21 columns]\n",
      "\n",
      "\n",
      "New, cleaned data stats: \n",
      "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
      "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
      "mean    53.510893  132.540305   198.799564    0.233115  136.809368   \n",
      "std      9.432617   17.989941   109.384145    0.423046   25.460334   \n",
      "min     28.000000   80.000000     0.000000    0.000000   60.000000   \n",
      "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
      "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
      "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
      "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
      "\n",
      "          Oldpeak  HeartDisease       Sex_F       Sex_M  ChestPainType_ASY  \\\n",
      "count  918.000000    918.000000  918.000000  918.000000         918.000000   \n",
      "mean     0.887364      0.553377    0.210240    0.789760           0.540305   \n",
      "std      1.066570      0.497414    0.407701    0.407701           0.498645   \n",
      "min     -2.600000      0.000000    0.000000    0.000000           0.000000   \n",
      "25%      0.000000      0.000000    0.000000    1.000000           0.000000   \n",
      "50%      0.600000      1.000000    0.000000    1.000000           1.000000   \n",
      "75%      1.500000      1.000000    0.000000    1.000000           1.000000   \n",
      "max      6.200000      1.000000    1.000000    1.000000           1.000000   \n",
      "\n",
      "       ...  ChestPainType_NAP  ChestPainType_TA  RestingECG_LVH  \\\n",
      "count  ...         918.000000        918.000000      918.000000   \n",
      "mean   ...           0.221133          0.050109        0.204793   \n",
      "std    ...           0.415236          0.218289        0.403770   \n",
      "min    ...           0.000000          0.000000        0.000000   \n",
      "25%    ...           0.000000          0.000000        0.000000   \n",
      "50%    ...           0.000000          0.000000        0.000000   \n",
      "75%    ...           0.000000          0.000000        0.000000   \n",
      "max    ...           1.000000          1.000000        1.000000   \n",
      "\n",
      "       RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  ExerciseAngina_Y  \\\n",
      "count         918.000000     918.000000        918.000000        918.000000   \n",
      "mean            0.601307       0.193900          0.595861          0.404139   \n",
      "std             0.489896       0.395567          0.490992          0.490992   \n",
      "min             0.000000       0.000000          0.000000          0.000000   \n",
      "25%             0.000000       0.000000          0.000000          0.000000   \n",
      "50%             1.000000       0.000000          1.000000          0.000000   \n",
      "75%             1.000000       0.000000          1.000000          1.000000   \n",
      "max             1.000000       1.000000          1.000000          1.000000   \n",
      "\n",
      "       ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
      "count     918.000000     918.000000   918.000000  \n",
      "mean        0.068627       0.501089     0.430283  \n",
      "std         0.252957       0.500271     0.495386  \n",
      "min         0.000000       0.000000     0.000000  \n",
      "25%         0.000000       0.000000     0.000000  \n",
      "50%         0.000000       1.000000     0.000000  \n",
      "75%         0.000000       1.000000     1.000000  \n",
      "max         1.000000       1.000000     1.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n",
      "\n",
      "\n",
      "Pair plots \n",
      "<seaborn.axisgrid.PairGrid object at 0x000002108DF43D00>\n",
      "\n",
      "\n",
      "Now running models to train and test data with new dataset.\n",
      "\n",
      "Accuracy score:  0.875\n",
      "F1 Score:  0.887\n",
      "Accuracy score:  0.864\n",
      "F1 Score:  0.876\n",
      "          Predicted +  Predicted -\n",
      "Actual +           71           14\n",
      "Actual -           11           88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86        85\n",
      "           1       0.87      0.91      0.89        99\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.87      0.87       184\n",
      "weighted avg       0.88      0.88      0.87       184\n",
      "\n",
      "Accuracy score:  0.886\n",
      "F1 Score:  0.897\n",
      "best score:  0.890907395729964\n",
      "best param:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 15, 'n_estimators': 100}\n",
      "\n",
      "Report on Ramdom Forest\n",
      "\n",
      "Accuracy score:  0.88\n",
      "F1 Score:  0.892\n",
      "[[71 14]\n",
      " [ 8 91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        85\n",
      "           1       0.87      0.92      0.89        99\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "          Predicted +  Predicted -\n",
      "Actual +           71           14\n",
      "Actual -            8           91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        85\n",
      "           1       0.87      0.92      0.89        99\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "\n",
      "Report on Ramdom Forest with only top 10 feautres\n",
      "\n",
      "Accuracy score:  0.864\n",
      "F1 Score:  0.876\n",
      "\n",
      "\n",
      "Cleaned data is saved to: \n",
      "data\\heartCleaned.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def makeDir():\n",
    "    path1 = \"images\"  # make a location to store images\n",
    "    path2 = \"data\"  # make a location to store images\n",
    "    # mkdir for images\n",
    "    try:\n",
    "        os.mkdir(path1)\n",
    "    except OSError:\n",
    "        print (\"\\nCreation of the directory '%s' failed; it already exists.\\n\" % path1)\n",
    "    else:\n",
    "        print (\"\\nSuccessfully created the directory '%s'\\n\" % path1)\n",
    "    # mkdir for cleaned data file\n",
    "    try:\n",
    "        os.mkdir(path2)\n",
    "    except OSError:\n",
    "        print (\"\\nCreation of the directory '%s' failed; it already exists.\\n\" % path2)\n",
    "    else:\n",
    "        print (\"\\nSuccessfully created the directory '%s'\\n\" % path2)\n",
    "\n",
    "def dataLoad():\n",
    "    file = 'data\\heart.csv'\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "def cleanedDataFile(df):\n",
    "    csv_path = f\"data\\heartCleaned.csv\"\n",
    "    df.to_csv(csv_path, sep= ',', index= False)\n",
    "    print(f\"\\n\\nCleaned data is saved to: \\n{csv_path}\")\n",
    "\n",
    "def eda(df):\n",
    "    print(f\"Basic stats on data:\\n{df.describe()}\\n\")\n",
    "    print(f\"Data info:\\n{df.info()}\\n\")\n",
    "    # check for dupes\n",
    "    print('\\nNumber of Duplicates:\\n', len(df[df.duplicated()]))\n",
    "    print(f\"\\nCounts\\n{df.count()}\\n\")\n",
    "    # check for dupe rows\n",
    "    print(f\"\\nValue Counts:\\n{df.value_counts()}\\nNulls:\\n{df.notna()}\\n\")\n",
    "    # examine unique values; look for binary variables and other non-continuous data\n",
    "    print(f\"\\nUnique values:\\n{df.nunique()}\\n\")\n",
    "    # checking for NaN values\n",
    "    print(f\"\\nNulls in cloumns: \\n{df.isna().sum()}\\n\")\n",
    "    # count for whole dataframe\n",
    "    print(f\"Number of nulls in entire dataset: {df.isna().sum().sum()}\\n\")\n",
    "    df.corr()\n",
    "def viz(df):\n",
    "    # Look for zeroes in datasets that may be unreasonable.\n",
    "    fig, axs = plt.subplots(len(df.columns), figsize=(5, 20))\n",
    "    for n, col in enumerate(df.columns):\n",
    "        # print(col)\n",
    "        a = df[col].hist(ax=axs[n])\n",
    "        a.set_title(col)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # cholesterol stood out with about 18% of the values being 0 - visualize\n",
    "    df.Cholesterol.plot(kind = \"hist\", bins = 20, figsize = (8,5))\n",
    "    plt.legend()\n",
    "    plt.savefig(\"images\\cholesterol.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Viz for title page \n",
    "    plt.figure(figsize=(20,20))\n",
    "    sns.displot(df['Age'], color=\"red\", label=\"Age\", kde= True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"images\\CVD_by_Age.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # look at correlations to target\n",
    "    targetHeatmap = sns.heatmap(\n",
    "        df.corr()[['HeartDisease']].sort_values(by='HeartDisease', ascending=False), \n",
    "        vmin=-0.5, vmax=1, annot=True, cmap='BrBG', fmt = '.2f'\n",
    "        )\n",
    "    fig = targetHeatmap.get_figure()\n",
    "    fig.savefig('images\\heartdiseaseCorr.png')\n",
    "    fig\n",
    "\n",
    "    # Look for outliers in numeric variables\n",
    "    col = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "    num_col = df[col]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize =(10, 10))\n",
    "    fig.patch.set_facecolor('#f1faee')\n",
    "\n",
    "    c = 1\n",
    "    for i in num_col.columns: \n",
    "        plt.subplot(3, 2, c)\n",
    "        plt.boxplot(num_col[i])\n",
    "        plt.title(i, fontsize=12, color='Black')\n",
    "        plt.suptitle('Numeric Variables', fontsize=20)\n",
    "        c = c + 1\n",
    "    fig.savefig('images\\outliers.png')\n",
    "    \n",
    "    # check categorical variables\n",
    "    heart_df = df[df['HeartDisease'] == 1]\n",
    "    fig, ax = plt.subplots(figsize =(10, 10))\n",
    "    fig.patch.set_facecolor('#f1faee')\n",
    "    fig.savefig('images\\categoricalHistograms.png')\n",
    "\n",
    "    j = 1\n",
    "    for i in heart_df.columns: \n",
    "        if heart_df[i].dtypes  == 'object':\n",
    "            plt.subplot(3, 2, j)\n",
    "            sns.countplot(y = heart_df[i], data = heart_df, order=heart_df[i].value_counts().index, palette='Blues_r', edgecolor='black')\n",
    "            #plt.title(i, fontsize=15, color='black')\n",
    "            plt.suptitle('Categorical Variables', fontsize=20)\n",
    "            j = j + 1\n",
    "def dataCleanTransform(df):\n",
    "    # through visualization found 1 zero value for blood pressure = dead\n",
    "    # impute mean value for 0 in the resting BP with the mean for that demographic\n",
    "    df.RestingBP.mask(df.RestingBP == 0, 132, inplace=True)\n",
    "    cleanedDF = df\n",
    "    # encode categorical variables\n",
    "    categorical = ['Sex','ChestPainType','RestingECG','ExerciseAngina','ST_Slope']\n",
    "    encoded = pd.get_dummies(cleanedDF[categorical])\n",
    "    print(encoded.info())\n",
    "    # joing original dataframe and encoded set of features\n",
    "    # create new dataframe and only assign columsn with numerical values\n",
    "    encodedDF = df.drop(columns=categorical)\n",
    "    encodedDF = encodedDF.join(encoded)\n",
    "    print(encodedDF)\n",
    "\n",
    "    print(f\"\\n\\nNew, cleaned data stats: \\n\"\n",
    "        f\"{encodedDF.describe()}\")\n",
    "    # get column names\n",
    "    headers = encodedDF.columns\n",
    "\n",
    "    # Visualize new dataframe with pairplots\n",
    "    # Feature Pair Plots\n",
    "    sns.pairplot(data=encodedDF,\n",
    "        x_vars=headers,\n",
    "        y_vars=headers,\n",
    "        diag_kind='kde'\n",
    "    )\n",
    "    # Too many features to see anything substantial; splitting into two\n",
    "    a = sns.pairplot(data=encodedDF.iloc[:,0:12],diag_kind='kde',corner=True)\n",
    "    a.savefig(\"images\\pairplot.png\")\n",
    "    b = sns.pairplot(data=encodedDF.iloc[:,13:],diag_kind='kde',corner=True)\n",
    "    b.savefig(\"images\\pairplot2.png\")\n",
    "    # b has no useful data, just print a\n",
    "    print(\n",
    "        f\"\\n\\nPair plots \\n\"\n",
    "        f\"{a}\"\n",
    "    )\n",
    "\n",
    "    # Heatmap\n",
    "    fig, ax = plt.subplots(figsize= (10,6))\n",
    "    corrImage = sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap= 'BrBG', annot=True)\n",
    "    fig = corrImage.get_figure()\n",
    "    fig.savefig('images/correlationHeatMap.png')\n",
    "\n",
    "    # The output above is not as clear as it could be. Let's mask some of the output.\n",
    "    # get upper triangle with NumPy method\n",
    "    np.triu(np.ones_like(df.corr()))\n",
    "    # set plot size\n",
    "    plt.figure(figsize=(16,6))\n",
    "    # create heatmap with lower triangle only\n",
    "    upper = np.triu(np.ones_like(df.corr(), dtype=np.bool_))\n",
    "    triangleHeatMap = sns.heatmap(\n",
    "        df.corr(), mask=upper, vmin=-0.5, vmax=1, annot=True, cmap='Blues'\n",
    "        )\n",
    "    fig = triangleHeatMap.get_figure()\n",
    "    fig.savefig('images/TriangleHeatMap.png')\n",
    "\n",
    "    return encodedDF\n",
    "\n",
    "def cleanedDataFile(df):\n",
    "    csv_path = f\"data\\heartCleaned.csv\"\n",
    "    df.to_csv(csv_path, sep= ',', index= False)\n",
    "    print(f\"\\n\\nCleaned data is saved to: \\n{csv_path}\\n\")\n",
    "\n",
    "def model(df):\n",
    "    # check counts for heart disease or not, and is it balanced or not?\n",
    "    round(df['HeartDisease'].value_counts()/len(df['HeartDisease'])*100)\n",
    "\n",
    "    # Dummy variables\n",
    "    pd.set_option('display.max_columns', 40)\n",
    "\n",
    "    # Select categorical variables\n",
    "    cat = df.select_dtypes(include=object).columns\n",
    "    df_dummy = pd.get_dummies(df, columns=cat)\n",
    "\n",
    "    inp = df_dummy.drop(columns='HeartDisease')\n",
    "    out = df_dummy['HeartDisease']\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        inp, out, test_size=0.20, random_state=20)\n",
    "    \n",
    "    # Log regression\n",
    "    log_reg = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "    y_pred_lr = log_reg.predict(x_test)\n",
    "    print('Accuracy score: ', round(accuracy_score(y_test, y_pred_lr), 3))\n",
    "    print('F1 Score: ', round(f1_score(y_test, y_pred_lr), 3))\n",
    "\n",
    "    # input, output var declarations \n",
    "    Y = df_dummy['HeartDisease']\n",
    "    X = df_dummy[['Age','RestingBP','Cholesterol','FastingBS','MaxHR','Oldpeak']]\n",
    "    columns = X.columns\n",
    "    # apply Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    X_std = pd.DataFrame(X_std, columns = columns)\n",
    "    # Dataset of all dummy columns\n",
    "    df2 = df_dummy.iloc[:,7:]\n",
    "    # Merge the Standardization column with dummy columns\n",
    "    X_nr = X_std.join(df2)\n",
    "\n",
    "    # train test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X_nr, Y, test_size=0.20, random_state=20)\n",
    "    \n",
    "    log_reg_nr = LogisticRegression(solver='liblinear').fit(x_train, y_train)\n",
    "    y_pred_lr_nr = log_reg_nr.predict(x_test)\n",
    "    print('Accuracy score: ', round(accuracy_score(y_test, y_pred_lr_nr), 3))\n",
    "    print('F1 Score: ', round(f1_score(y_test, y_pred_lr_nr), 3))\n",
    "\n",
    "    # Confusion Matrix for Logistic Regression¶\n",
    "    predictedLabels: np.ndarray = log_reg_nr.predict(x_test)\n",
    "    confusionMatrixDF: pd.DataFrame = pd.DataFrame(metrics.confusion_matrix(y_test,predictedLabels),index=['Actual +','Actual -'],columns=['Predicted +', 'Predicted -'])\n",
    "    print(confusionMatrixDF)\n",
    "    print(metrics.classification_report(y_test, y_pred_lr))\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(random_state=20, n_estimators=100)\n",
    " \n",
    "    # x_train, x_test, y_train, y_test\n",
    "    rf = rf.fit(x_train, y_train)\n",
    "    y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "    print('Accuracy score: ', round(accuracy_score(y_test, y_pred_rf), 3))\n",
    "    print('F1 Score: ', round(f1_score(y_test, y_pred_rf), 3))\n",
    "\n",
    "    # Tune the model with grid search\n",
    "    n_estimators = [100, 200, 300]\n",
    "    max_depth = [10, 20, 30]\n",
    "    max_depth.append(None)\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    min_samples_split = [5, 10, 15]\n",
    "    min_samples_leaf = [1, 2]\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    params = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "            'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "\n",
    "    RF = RandomForestClassifier(random_state=20)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator = RF, \n",
    "                            param_grid = params,\n",
    "                            scoring = 'f1',\n",
    "                            cv = 5,\n",
    "                            verbose=0, \n",
    "                            n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print(\"best score: \", grid_search.best_score_)\n",
    "    print(\"best param: \", grid_search.best_params_)\n",
    "\n",
    "    # apply best params to the RF model\n",
    "    best_para = grid_search.best_params_\n",
    "    rf_2 = RandomForestClassifier(random_state=20, **best_para)\n",
    "                                \n",
    "    rf_2 = rf_2.fit(x_train, y_train)\n",
    "    y_pred_rf_2 = rf_2.predict(x_test)\n",
    "    print(f'\\nReport on Ramdom Forest\\n')\n",
    "    print('Accuracy score: ', round(accuracy_score(y_test, y_pred_rf_2), 3))\n",
    "    print('F1 Score: ', round(f1_score(y_test, y_pred_rf_2), 3))\n",
    "\n",
    "    # Confusion matrix and report for RF\n",
    "    print(metrics.confusion_matrix(y_test, y_pred_rf_2))\n",
    "    print(metrics.classification_report(y_test, y_pred_rf_2))\n",
    "\n",
    "    # predictedLabels: np.ndarray = log_reg_nr.predict(x_test)\n",
    "    confusionMatrixDF: pd.DataFrame = pd.DataFrame(metrics.confusion_matrix(y_test,y_pred_rf_2),index=['Actual +','Actual -'],columns=['Predicted +', 'Predicted -'])\n",
    "    print(confusionMatrixDF)\n",
    "    print(metrics.classification_report(y_test, y_pred_rf_2))\n",
    "\n",
    "    # See what SKlearn says are important features with dummy variables in model\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "    plt.figure(figsize=(15,8))\n",
    "    imp = mutual_info_classif(inp, out)\n",
    "    feature_imp = pd.Series(imp, df_dummy.columns[0:len(df_dummy.columns)-1])\n",
    "    feature_imp = feature_imp.sort_values(ascending=True)\n",
    "    feature_imp.plot(kind = 'barh', color = 'teal')\n",
    "    plt.title(\"Feature importance plot\")\n",
    "    plt.savefig(\"images\\\\featureImportance.png\")\n",
    "\n",
    "    # See impact of using only the top 10 features\n",
    "    best_feat_df = df_dummy[['ST_Slope_Flat','Sex_M','ST_Slope_Down','RestingECG_ST','ExerciseAngina_N', \n",
    "                            'Oldpeak','ChestPainType_ASY','MaxHR','Sex_F','Cholesterol','HeartDisease']]\n",
    "\n",
    "    inp_feat = best_feat_df.drop(columns='HeartDisease')\n",
    "    out_feat = best_feat_df['HeartDisease']\n",
    "\n",
    "    x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(\n",
    "        inp_feat, out_feat, test_size=0.20, random_state=20)\n",
    "    \n",
    "    rf_feat = RandomForestClassifier(random_state=20, n_estimators=100)\n",
    " \n",
    "    rf_feat = rf_feat.fit(x_train_2, y_train_2)\n",
    "    y_pred_rf_feat = rf_feat.predict(x_test_2)\n",
    "    print(f'\\nReport on Ramdom Forest with only top 10 feautres\\n')\n",
    "    print('Accuracy score: ', round(accuracy_score(y_test_2, y_pred_rf_feat), 3))\n",
    "    print('F1 Score: ', round(f1_score(y_test_2, y_pred_rf_feat), 3))\n",
    "\n",
    "def main():\n",
    "    makeDir()\n",
    "    dataFrame = dataLoad()\n",
    "    eda(dataFrame)\n",
    "    viz(dataFrame)\n",
    "    newDF = dataCleanTransform(dataFrame)\n",
    "\n",
    "    # ''' Comment out for now'''\n",
    "    # # # This library captures many EDA elements\n",
    "    # # # https://pandas-profiling.github.io/pandas-profiling/docs/master/index.html\n",
    "    # # profile = ProfileReport(dataFrame, title=\"Cardiovascular Disease Data Profiling Report\", explorative=True)\n",
    "    # # # export for report\n",
    "    # # profile.to_file(\"CVD.html\")\n",
    "    # # # print to screen in interactive frame\n",
    "    # # # 3.1 widgets() is broken; regress to 3.0 for widgets or use to_notebook_iframe (CAO: Nov 2021)\n",
    "    # # # Selecting alternative path since user action required to rollback version\n",
    "    # # profile.to_notebook_iframe()\n",
    "    # '''end comment'''\n",
    "    print(f\"\\n\\nNow running models to train and test data with new dataset.\\n\")\n",
    "    model(newDF)\n",
    "    cleanedDataFile(newDF)     \n",
    "    # # run other notebooks in library\n",
    "    # # %run ./eda.ipynb\n",
    "    # # %run ./models.ipynb\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
